{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2b3ecf3f",
   "metadata": {},
   "source": [
    "# Portfolio assignment week 7\n",
    "\n",
    "## 1. Bagging vs Boosting\n",
    "The scikit-learn library provides several options for bagging and boosting. It is possible to create your own boosting model based on a base model. For instance, you can create a tree based bagging model. In addition, scikit-learn provides AdaBoost. For XGBoost it is best to use the xgboost library.\n",
    "\n",
    "Based on the theory in the [accompanying notebook](../Exercises/E_BAGGING_BOOSTING.ipynb), create a bagging, boosting and dummy classifier. Test these classifiers on the [breast cancer dataset](https://www.kaggle.com/datasets/yasserh/breast-cancer-dataset). Go through the data science pipeline as you've done before:\n",
    "\n",
    "1. Try to understand the dataset globally.\n",
    "2. Load the data.\n",
    "3. Exploratory analysis\n",
    "4. Preprocess data (skewness, normality, etc.)\n",
    "5. Modeling (cross-validation and training). (**Create several bagging classifiers with different estimators**.)\n",
    "6. Evaluation (**Use the evaluation methods as described in the previous lessons. Then compare the different models**.)\n",
    "7. Try to understand why some methods perform better than others. Try different configurations for your bagging and boosting models.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7516093b",
   "metadata": {},
   "source": [
    "**1. Try to understand the dataset globally**\n",
    "\n",
    "The breast cancer dataset contains information that can be applied to binary classification prediction of breast cancer. The dataset consists of 568 patients with either a malignent or benign breast tumor. For each patient information about 30 tumor parameters is provided. These parameters can be used to create a predictive model for classifying malignent vs benign tumors using machine learning.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f4b4a8c",
   "metadata": {},
   "source": [
    "**2. Load the data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6add71af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ce553466",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading data\n",
    "import yaml\n",
    "\n",
    "def get_config():\n",
    "    with open(\"config.yaml\", 'r') as stream:\n",
    "        config = yaml.safe_load(stream)\n",
    "    return config\n",
    "\n",
    "config = get_config()\n",
    "data = (config['breast-cancer'])\n",
    "df = pd.read_csv(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d084c02",
   "metadata": {},
   "source": [
    "**3. Exploratory analysis**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5e8cd381",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of malignent tumors: 212\n",
      "Number of benign tumors: 357\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 569 entries, 0 to 568\n",
      "Data columns (total 32 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   id                       569 non-null    int64  \n",
      " 1   diagnosis                569 non-null    object \n",
      " 2   radius_mean              569 non-null    float64\n",
      " 3   texture_mean             569 non-null    float64\n",
      " 4   perimeter_mean           569 non-null    float64\n",
      " 5   area_mean                569 non-null    float64\n",
      " 6   smoothness_mean          569 non-null    float64\n",
      " 7   compactness_mean         569 non-null    float64\n",
      " 8   concavity_mean           569 non-null    float64\n",
      " 9   concave points_mean      569 non-null    float64\n",
      " 10  symmetry_mean            569 non-null    float64\n",
      " 11  fractal_dimension_mean   569 non-null    float64\n",
      " 12  radius_se                569 non-null    float64\n",
      " 13  texture_se               569 non-null    float64\n",
      " 14  perimeter_se             569 non-null    float64\n",
      " 15  area_se                  569 non-null    float64\n",
      " 16  smoothness_se            569 non-null    float64\n",
      " 17  compactness_se           569 non-null    float64\n",
      " 18  concavity_se             569 non-null    float64\n",
      " 19  concave points_se        569 non-null    float64\n",
      " 20  symmetry_se              569 non-null    float64\n",
      " 21  fractal_dimension_se     569 non-null    float64\n",
      " 22  radius_worst             569 non-null    float64\n",
      " 23  texture_worst            569 non-null    float64\n",
      " 24  perimeter_worst          569 non-null    float64\n",
      " 25  area_worst               569 non-null    float64\n",
      " 26  smoothness_worst         569 non-null    float64\n",
      " 27  compactness_worst        569 non-null    float64\n",
      " 28  concavity_worst          569 non-null    float64\n",
      " 29  concave points_worst     569 non-null    float64\n",
      " 30  symmetry_worst           569 non-null    float64\n",
      " 31  fractal_dimension_worst  569 non-null    float64\n",
      "dtypes: float64(30), int64(1), object(1)\n",
      "memory usage: 142.4+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Displaying number of malignent vs benign\n",
    "print(f'\\nNumber of malignent tumors: {len(df[df.diagnosis == \"M\"])}')\n",
    "print(f'Number of benign tumors: {len(df[df.diagnosis == \"B\"])}\\n')\n",
    "    \n",
    "# Displaying number of columns and rows, datatypes, missing values\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a5b1078",
   "metadata": {},
   "source": [
    "**4. Preprocess data (skewness, normality, etc.)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16f60fd8",
   "metadata": {},
   "source": [
    "The features have varying ranges and should be scaled. The diagnosis (y) should be converted from catergorical variables to a numerical representation. The preprocessed data is then split into training and testing sets for modelling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0d934394",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(['id', 'diagnosis'], axis = 1)\n",
    "\n",
    "# Scaling the features\n",
    "scaler = MinMaxScaler()\n",
    "X_scaled = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "35d93134",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['diagnosis']\n",
    "\n",
    "# Encoding the \"diagnosis\" column\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "21baac7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y_encoded, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bf82ac3",
   "metadata": {},
   "source": [
    "**5. Modeling (cross-validation and training). Create several bagging classifiers with different estimators.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d3fcecf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier: Mean Accuracy: 0.949, Standard Deviation: 0.031\n",
      "RandomForestClassifier: Mean Accuracy: 0.958, Standard Deviation: 0.018\n",
      "ExtraTreesClassifier: Mean Accuracy: 0.965, Standard Deviation: 0.020\n"
     ]
    }
   ],
   "source": [
    "# Create a list of base estimators\n",
    "base_estimators = [\n",
    "    DecisionTreeClassifier(),\n",
    "    RandomForestClassifier(n_estimators=100),\n",
    "    ExtraTreesClassifier(n_estimators=100)\n",
    "]\n",
    "\n",
    "# Create a dictionary of bagging classifiers with different base estimators\n",
    "bagging_classifiers = {}\n",
    "for base_estimator in base_estimators:\n",
    "    bagging_classifier = BaggingClassifier(base_estimator, n_estimators=10)\n",
    "    classifier_name = base_estimator.__class__.__name__\n",
    "    bagging_classifiers[classifier_name] = bagging_classifier\n",
    "\n",
    "# Evaluate each bagging classifier using cross-validation\n",
    "for classifier_name, bagging_classifier in bagging_classifiers.items():\n",
    "    scores = cross_val_score(bagging_classifier, X, y, cv=5)\n",
    "    print(f\"{classifier_name}: Mean Accuracy: {scores.mean():.3f}, Standard Deviation: {scores.std():.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0319d74f",
   "metadata": {},
   "source": [
    "ExtraTreesClassifiers has the highest mean accuracy. RandomForestClassifier has the lowest standard deviation. DecisionTreeClassifier appears be the least accurate."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e496040",
   "metadata": {},
   "source": [
    "**6. Evaluation (Use the evaluation methods as described in the previous lessons. Then compare the different models.)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "38085aec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "DecisionTreeClassifier Bagging Classifier:\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.97      0.97        71\n",
      "           1       0.95      0.93      0.94        43\n",
      "\n",
      "    accuracy                           0.96       114\n",
      "   macro avg       0.96      0.95      0.95       114\n",
      "weighted avg       0.96      0.96      0.96       114\n",
      "\n",
      "Confusion Matrix:\n",
      "[[69  2]\n",
      " [ 3 40]]\n",
      "\n",
      "RandomForestClassifier Bagging Classifier:\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.99      0.97        71\n",
      "           1       0.98      0.93      0.95        43\n",
      "\n",
      "    accuracy                           0.96       114\n",
      "   macro avg       0.97      0.96      0.96       114\n",
      "weighted avg       0.97      0.96      0.96       114\n",
      "\n",
      "Confusion Matrix:\n",
      "[[70  1]\n",
      " [ 3 40]]\n",
      "\n",
      "ExtraTreesClassifier Bagging Classifier:\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.99      0.98        71\n",
      "           1       0.98      0.95      0.96        43\n",
      "\n",
      "    accuracy                           0.97       114\n",
      "   macro avg       0.97      0.97      0.97       114\n",
      "weighted avg       0.97      0.97      0.97       114\n",
      "\n",
      "Confusion Matrix:\n",
      "[[70  1]\n",
      " [ 2 41]]\n"
     ]
    }
   ],
   "source": [
    "# Train and evaluate the models\n",
    "for classifier_name, bagging_classifier in bagging_classifiers.items():\n",
    "    bagging_classifier.fit(X_train, y_train)\n",
    "    y_pred = bagging_classifier.predict(X_test)\n",
    "    \n",
    "    print(f\"\\n{classifier_name} Bagging Classifier:\")\n",
    "    # Classification report\n",
    "    print(\"Classification Report:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    \n",
    "    # Confusion matrix\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52f738d2",
   "metadata": {},
   "source": [
    "The ExtraTreesClassifier Bagging Classifier achieves the highest precision, recall, F1-score, and accuracy among the three classifiers. It shows a better performance in correctly identifying both the positive (malignant) and negative (benign) cases.\n",
    "\n",
    "The RandomForestClassifier Bagging Classifier also performs well, especially in terms of recall, with a high percentage of true positives correctly classified as malignant.\n",
    "\n",
    "The DecisionTreeClassifier Bagging Classifier has slightly lower recall compared to the other classifiers. It still appears to be performing well. \n",
    "\n",
    "The performance differences between the classifiers can be explained by the characteristics of the base estimators and the variability introduced by the bagging technique. Decision trees tend to have high variance but can capture complex relationships. Random forests combine multiple decision trees to reduce variance and improve performance. Extra trees further enhance this approach by using additional randomness in the tree-building process. This is why the ExtraTreesClassifier seems to be performing the best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8f431ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Further optimising TreeClassifiers\n",
    "base_estimators = [\n",
    "    ExtraTreesClassifier(n_estimators=100)\n",
    "]\n",
    "\n",
    "# Define the parameter grid for hyperparameter tuning\n",
    "param_grid = {\n",
    "    'n_estimators': [10, 50, 100],\n",
    "    'estimator__max_depth': [None, 3, 5, 7]\n",
    "}\n",
    "\n",
    "# Perform grid search to find the best hyperparameters for each bagging classifier\n",
    "for classifier_name, bagging_classifier in bagging_classifiers.items():\n",
    "    grid_search = GridSearchCV(bagging_classifier, param_grid, cv=5)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    \n",
    "    # Get the best hyperparameters and score\n",
    "    best_params = grid_search.best_params_\n",
    "    best_score = grid_search.best_score_\n",
    "    \n",
    "    print(f\"\\n{classifier_name} Bagging Classifier:\")\n",
    "    print(\"Best Hyperparameters:\", best_params)\n",
    "    print(\"Best Score:\", best_score)\n",
    "    \n",
    "    # Train and evaluate the bagging classifier with the best hyperparameters\n",
    "    bagging_classifier.set_params(**best_params)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
